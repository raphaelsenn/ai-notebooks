{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIONAL AGENTS\n",
    "\n",
    "## Topics\n",
    "\n",
    "* Rational agents\n",
    "* Rationallity\n",
    "* Structure of an AI agent\n",
    "* PEAS Representation\n",
    "* Agent environment in AI\n",
    "* Example implementation of vacuum cleaner\n",
    "\n",
    "## Rational agents\n",
    "\n",
    "### Definition: Rational agent\n",
    "For each possible percept sequence, a rational agent should select an action that is expected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has.\n",
    "\n",
    "#### Rationality:\n",
    "The rationality of an agent is measured by its performance measures. Rationality can be judged on the basis of follwoing points:\n",
    "\n",
    "* Performance measures (goals)\n",
    "* Percept sequences\n",
    "* Knowledge of the environment\n",
    "* Possible actions\n",
    "\n",
    "An ideal rational agent acts upon the function:\n",
    "\n",
    "| Percept Sequence x Word Knowledge -> Action |\n",
    "| --------------------------------------------|\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "| Agent Type | Performance Measures | Environment | Actuators | Sensors |\n",
    "| ----------------- | ------------------- | ----------- | ----------- | ------------ |\n",
    "| vacuum cleaner  | cleanness, battery life, efficency | room, carpet, wood floor, obstacles | wheels, brushes, vacuum extractor | camera, dirt sensor, infrared sensor |\n",
    "| medical diagnose system  | healthy patient, minimize costs | hospital, patient, staff | tests, treatments | keyboard (typing in symptoms) |\n",
    "\n",
    "\n",
    "### Structure of rational agents\n",
    "\n",
    "Realization of a rational agent through an\n",
    " * Agent program, executed on an\n",
    " * Architecture which also provides an interface to the environment (percepts, actions)\n",
    "\n",
    "| Agent = Architecture + Program |\n",
    "| --------------------------------------------|\n",
    "\n",
    "### The Environment of rational agents\n",
    "\n",
    "| Environment Type | |\n",
    "| --------------------------- | ---------------------------------------------------------------------- |\n",
    "| Accessible vs. inaccessible | Are the relevant aspects of the environment accessible to the sensors? |\n",
    "| Deterministic vs. stochastic | Is the next state of the environment completely determined by the current state and the selected action? If only actions of other agents are nondeterministic, the environment is called strategic. |\n",
    "| Episodic vs. sequential | Can the quality of an action be evaluated within an episode (perception + action), or are future developments decisive for the evaluation of quality? |\n",
    "| Static vs. dynamic | Can the environment change while the agent is deliberating? If the environment does not change but if the agentâ€™s performance score changes as time passes by the environment is denoted as semi-dynamic. |\n",
    "| Discrete vs. continuous | Is the environment discrete (chess) or continuous (a robot moving in a room)? |\n",
    "| Single agent vs. multi-agent | Which entities have to be regarded as agents? There are competitive and cooperative scenarios |\n",
    "\n",
    "#### Examples of Environments\n",
    "\n",
    "| Task | Observable | Deterministic | Episodic | Static | Discrete | Agents |\n",
    "| ----------------- | -------------- | ------ | ------ | --------- | -------| --------- | \n",
    "| Crossword puzzle | Observable | Deterministic | Episodic | Static | Discrete | Agents |\n",
    "| Medical diagnosis | Observable | Deterministic | Episodic | Static | Discrete | Agents |\n",
    "\n",
    "\n",
    "## Different classes of agents\n",
    " * Table-Driven agents\n",
    " * Simple Reflex agents\n",
    " * Model based reflex agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {('A', 'clean'): 'right', \n",
    "         ('A', 'dirty'): 'clean',\n",
    "         ('B', 'clean'): 'left',\n",
    "         ('B', 'dirty'): 'clean'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table driven agents\n",
    "\n",
    "![image](../images/table_driven_agent.png)\n",
    "\n",
    "#### Problem: The tables can become very large and it would take much time to design it for harder problems... practically impossible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "percepts = []\n",
    "\n",
    "def lookup(percepts, table):\n",
    "    action = table[percepts]\n",
    "    return action\n",
    "\n",
    "def table_driven_agent(percept):\n",
    "    percepts.append(percept)\n",
    "    action = lookup(percept, table)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percepts\tAction\n",
      "('A', 'dirty')\tclean\n",
      "('A', 'clean')\tright\n",
      "('B', 'dirty')\tclean\n",
      "('B', 'clean')\tleft\n",
      "[('A', 'dirty'), ('A', 'clean'), ('B', 'dirty'), ('B', 'clean')]\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    print('Percepts\\tAction')\n",
    "\n",
    "    # Possible scenario: \n",
    "    percept = ('A', 'dirty') \n",
    "    action = table_driven_agent(percept)\n",
    "    print(f\"{percept}\\t{action}\")\n",
    "\n",
    "    percept = ('A', 'clean') \n",
    "    action = table_driven_agent(percept)\n",
    "    print(f\"{percept}\\t{action}\")\n",
    "\n",
    "    percept = ('B', 'dirty') \n",
    "    action = table_driven_agent(percept)\n",
    "    print(f\"{percept}\\t{action}\")\n",
    "\n",
    "    percept = ('B', 'clean') \n",
    "    action = table_driven_agent(percept)\n",
    "    print(f\"{percept}\\t{action}\")\n",
    "run()\n",
    "print(percepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Reflex Agent\n",
    "\n",
    "\n",
    "![image](../images/simple_reflex_agent1.png)\n",
    "\n",
    "Direct use of perceptions is often not possible due to the large space required to store them (e.g., video images).\n",
    "\n",
    "Input therefore is often interpreted before decisions are made.\n",
    "\n",
    "![image](../images/simple_reflex_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = {'A': 'dirty', 'B': 'clean', 'C': 'dirty'}\n",
    "\n",
    "rules = {'clean': 'move', 'dirty': 'clean'}\n",
    "\n",
    "def interpret_input(percept):\n",
    "    pass \n",
    "\n",
    "def rule_match(state, rules):\n",
    "    pass\n",
    "\n",
    "def simple_reflex_agent(percept):\n",
    "    pass\n",
    "\n",
    "def run():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based Reflex Agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
