{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Motivation: Prediction whether a person getting Diabetes\n",
    "* For classification we should only accept output y = 0 (no diabetes) and y = 1 (diabetes).\n",
    "* Linear Regression is not suitable for this kind of task, because LinearRegression generates continues output.\n",
    "* We want output: $0 <= \\sigma(x) <= 1$ (where $\\sigma$ is our model).\n",
    "\n",
    "## The Sigmoid function\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$sigmoid(z)= \\frac{1}{1+e^{-z}}$}\n",
    "$$\n",
    "\n",
    "\n",
    "## Logistic Regression Model\n",
    "\n",
    "Standard Linear Regression model: $h_{w}(x)=w^{T}x$\n",
    "\n",
    "A subtile change introduces non-linearity:\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$\\sigma_{w}(x)= \\frac{1}{1+e^{-h_{w}(x)}} = \\frac{1}{1+e^{-w^{T}x}}$}\n",
    "$$\n",
    "\n",
    "## Interpretation of Model Output\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$\\sigma_{w}(x) \\approx$ estimated probability, that $y = 1$}\n",
    "$$\n",
    "\n",
    "More formally, we work with a __hypothesis__:\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$\\sigma_{w}(x) = P(y = 1 | x; w )$}\n",
    "$$\n",
    "\n",
    "\n",
    "The Probability that $y = 1$, that the input is $x$ and the model is parameeteriized by $w$.\n",
    "\n",
    "The actual labels are still discrete ($y=0$ or $y=1$), but the probabilities need to add to one:\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$P(y = 0 | x; w ) + P(y = 1 | x ; w) = 1$}\n",
    "$$\n",
    "\n",
    "## Loss Function of Logistic Regression\n",
    "\n",
    "Proposed loss function (specifically adapted to logistic regression):\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$J(\\sigma_{w}(x_{i}), y_{i}) = y_{i}log(\\sigma_{w}(x_{i}))-(1-y_{i})log(1-\\sigma_{w}(x_{i}))$}\n",
    "$$\n",
    "\n",
    "* J is konvex, but there is no analytical solution\n",
    "\n",
    "## Loss to minimize\n",
    "\n",
    "$$ \n",
    "\\Large \\text{$argmin_{w}J(w) = argmin_{w} \\sum_{i=1}^{N} y_{i}log(\\sigma_{w}(x_{i}))-(1-y_{i})log(1-\\sigma_{w}(x_{i}))$}\n",
    "$$\n",
    "\n",
    "## Gradient for Logistic Regression\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w})}{\\partial \\mathbf{w}} = \\frac{\\partial}{\\partial \\mathbf{w}} \\left[ \\sum_{i=1}^{N} -y_i \\log(\\sigma_{\\mathbf{w}}(\\mathbf{x}_i)) - (1 - y_i) \\log(1 - \\sigma_{\\mathbf{w}}(\\mathbf{x}_i)) \\right]\n",
    "$$\n",
    "\n",
    "Expanding this gradient, we get:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w})}{\\partial \\mathbf{w}} = \\sum_{i=1}^{N} - (y_i - \\sigma_{\\mathbf{w}}(\\mathbf{x}_i)) \\mathbf{x}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import depandancies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skin fold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Class variable (0 or 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  \\\n",
       "0                         6   \n",
       "1                         1   \n",
       "2                         8   \n",
       "3                         1   \n",
       "4                         0   \n",
       "\n",
       "   Plasma glucose concentration a 2 hours in an oral glucose tolerance test  \\\n",
       "0                                                148                          \n",
       "1                                                 85                          \n",
       "2                                                183                          \n",
       "3                                                 89                          \n",
       "4                                                137                          \n",
       "\n",
       "   Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  \\\n",
       "0                                72                                35   \n",
       "1                                66                                29   \n",
       "2                                64                                 0   \n",
       "3                                66                                23   \n",
       "4                                40                                35   \n",
       "\n",
       "   2-Hour serum insulin (mu U/ml)  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                              94   \n",
       "4                             168   \n",
       "\n",
       "   Body mass index (weight in kg/(height in m)^2)  Diabetes pedigree function  \\\n",
       "0                                            33.6                       0.627   \n",
       "1                                            26.6                       0.351   \n",
       "2                                            23.3                       0.672   \n",
       "3                                            28.1                       0.167   \n",
       "4                                            43.1                       2.288   \n",
       "\n",
       "   Age (years)  Class variable (0 or 1)  \n",
       "0           50                        1  \n",
       "1           31                        0  \n",
       "2           32                        1  \n",
       "3           21                        0  \n",
       "4           33                        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading example data (note: we dont care much about data cleaning here, just about how LR works)\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "X = df.drop(columns=['Class variable (0 or 1)'])\n",
    "y = df['Class variable (0 or 1)']\n",
    "\n",
    "print(f'Shape of X: {X.shape}')\n",
    "print(f'Shape of y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (614, 8)\n",
      "Shape of y_train: (614,)\n",
      "Shape of X_test: (154, 8)\n",
      "Shape of y_test: (154,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split for training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "print(f'Shape of y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, n_features: int) -> None:\n",
    "        self.w = np.random.rand(n_features+1)\n",
    "\n",
    "    def add_bias(self, X: np.array) -> np.array:\n",
    "        bias_column = np.ones((X.shape[0], 1))\n",
    "        return np.hstack((bias_column, X))\n",
    "\n",
    "    def sigmoid(self, z: np.array) -> np.array:\n",
    "        z = np.clip(z, -500, 500)  # Clip values to avoid overflow\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "    \n",
    "    def step(self, X: np.array) -> np.array:\n",
    "        return np.array([1 if x >= 0.5 else 0 for x in X])\n",
    "\n",
    "    def train(self, X: np.array, y: np.array, learning_rate: float, max_iter: int, verbose=False) -> None:\n",
    "        X_b = self.add_bias(X)\n",
    "        for iter in range(max_iter):\n",
    "            h_w = np.dot(X_b, self.w)                           # (N x n_in+1) * (n_in+1,) = (N,)\n",
    "            sigma_w = self.sigmoid(h_w)                         # (N,)\n",
    "            \n",
    "            J_w = -np.dot((y - sigma_w), X_b) / len(X_b)        # (N,) * (N x n_in+1) = (n_in+1,)\n",
    "            self.w = self.w - learning_rate * J_w               # (N,)\n",
    "\n",
    "            if verbose and iter % 1000 == 0:\n",
    "                epsilon = 1e-15 \n",
    "                sigma_w = np.clip(sigma_w, epsilon, 1 - epsilon)\n",
    "                loss = -np.mean(y * np.log(sigma_w) + (1 - y) * np.log(1 - sigma_w))\n",
    "                print(f'Iteration: {iter}, Loss: {loss}')\n",
    "\n",
    "    def predict(self, x: np.array) -> np.array:\n",
    "        x_b = self.add_bias(x)\n",
    "        z = np.dot(x_b, self.w)\n",
    "        sigma_w = self.sigmoid(z)\n",
    "        return self.step(sigma_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 22.107578770341963\n",
      "Iteration: 1000, Loss: 1.2732021185892322\n",
      "Iteration: 2000, Loss: 0.9358336732037364\n",
      "Iteration: 3000, Loss: 0.8566963458223563\n",
      "Iteration: 4000, Loss: 0.8177441404443307\n",
      "Iteration: 5000, Loss: 0.7874535741290457\n",
      "Iteration: 6000, Loss: 0.7613340421304262\n",
      "Iteration: 7000, Loss: 0.7385024975987664\n",
      "Iteration: 8000, Loss: 0.71871574197769\n",
      "Iteration: 9000, Loss: 0.7018212621348132\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = LogisticRegression(8)\n",
    "\n",
    "# Start training the logistic regresssion model\n",
    "model.train(X_train, y_train, learning_rate=0.0001, max_iter=10000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "def calculate_accuracy(X_test: np.array, y_test: np.array) -> float:\n",
    "    y_pred = model.predict(X_test)\n",
    "    return np.mean(y_test == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model_acc = calculate_accuracy(X_test, y_test)\n",
    "print(f'Accuracy: {model_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
