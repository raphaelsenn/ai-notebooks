{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a binary classification dataset\n",
    "X, y = make_classification(n_samples=1000,   # Number of samples\n",
    "                           n_features=20,    # Number of features\n",
    "                           n_informative=15, # Number of informative features\n",
    "                           n_redundant=5,    # Number of redundant features\n",
    "                           n_classes=2,      # Binary classification\n",
    "                           random_state=42)  # Seed for reproducibility\n",
    "\n",
    "# Convert labels from {0, 1} to {-1, 1}\n",
    "y = np.where(y == 0, -1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 20)\n",
      "y_train shape: (800,)\n",
      "X_test shape: (200, 20)\n",
      "y_test shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_estimators: int=100) -> None:\n",
    "        self.n_estimators = n_estimators\n",
    "        self.weights = [] \n",
    "        self.alphas = [] \n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self,\n",
    "            X: np.ndarray,\n",
    "            y: np.ndarray) -> None:\n",
    "\n",
    "        self.weights = np.array([1. / X.shape[0] for _ in range(X.shape[0])])\n",
    "        self.alphas = [] \n",
    "        self.trees = []\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            clf = DecisionTreeClassifier(max_depth=1)\n",
    "            clf.fit(X, y, sample_weight=self.weights)\n",
    "            y_pred = clf.predict(X)\n",
    "\n",
    "            indicator = np.where(y != y_pred, 1, 0) \n",
    "            eps = np.sum(self.weights * indicator) / np.sum(self.weights)\n",
    "            eps = max(eps, 1e-8) \n",
    "            alpha = np.log((1 - eps) / eps)\n",
    "            self.weights = self.weights * np.exp(alpha * indicator)\n",
    "\n",
    "            self.alphas.append(alpha)\n",
    "            self.trees.append(clf)\n",
    "\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        out = np.array([alpha * clf.predict(x) for alpha, clf in zip(self.alphas, self.trees)])\n",
    "        out = np.sum(out, axis=0) \n",
    "        return np.sign(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=100)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "r2 = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(n_estimators=100)\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "r2 = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
